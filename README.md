# local-llm
The code uses LangChain to run a large language model (mistral 7B) locally without GPU
# Step 1 
create a virtual environment with Python>3.10
install depensises Langchain and llama-cpp-python
# optional step  
go to https://huggingface.co/ find the model you wish to try get the repo id and filename and change it to the code
# step 3
run the code 
the model will be downloaded locally and you can start using your locall llm
