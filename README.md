# local-llm
The code uses LangChain to run a large language model (mistral 7B) locally without GPU following 
steps are not brief but summarised
# Step 1 
create a virtual environment with Python>3.10
install the Langchain and llama-cpp-python libraries
# optional step  
go to https://huggingface.co/ find the model you wish to try get the repo ID and filename and change it to the code
# step 3
run the code 
the model will be downloaded locally once completed you can start using your local llm
